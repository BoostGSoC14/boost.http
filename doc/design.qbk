[chapter Design choices
[quickbook 1.6]
]

[section FAQ]

[variablelist

[[Why build on top of Boost.Asio?]

 [One of the requirements of Boost.Http is scalable performance. Scalable
 performance requires an asynchronous design. Asio is expected to become the
 future C++ standard for sockets. So, Asio it is.

 Also, reuse existing std or Boost components is nice and Asio is the Boost
 solution for asynchronous socket I/O.]]

[[Why C++11?]

 [Asynchronous code can be largely simplified with language support for
 lambdas. To speed up the development (and decrease bugs), C++11 was chosen, but
 interface-wise, the only real C++11 feature is enum classes, which can be
 emulated in C++98 easily.

 C++98 support might be added later. The priority is to prove the core set of
 abstractions is correct. Then I can move on the task to fatten the library. The
 proof comes in the act of passing the Boost review process.

 To be fair, I also depend on the C++11 definition of `multimap`, but Boost
 containers can do the job easily.]]

[[Have you considered contribute to ['project X/Y]?]
 [[@https://github.com/vinipsmaker/gsoc2014-boost/blob/master/other_frameworks.md Yes, I have].

 But current Boost.Http is not like what I was expecting when I started to
 writing it. Boost.Http is better. The gap between Boost.Http and other projects
 became even larger. My previous research won't mention every difference.

 Boost.Http supports pipelining. Pion has separate functions for
 chunking. Boost.Http is designed for multiple backends. POCO, QtHttp and
 Casablanca aren't build on top of Asio. Pion and cpp-netlib will use their own
 thread-pool, instead adhering to Asio threading model.]]

[[Why is it only server-side?]

 [Server-side and client-side are of interest to different
 applications. Initially, the focus was to provide a library just to
 server-side, but with the time spent on research and development, it became
 apparent that many of the proposed abstractions are also useful for
 client-side.

 After this fact, a lot of caution was devoted to design the interface to retain
 the usefulness in client-side, where it makes sense. But this is not enough. A
 lot of time was spent on research just to get the server-side right and I
 expect that much time (or more) to also get the client-side right.

 Before any serious effort is spent on client-side, I want to focus on
 server-side, where the application load may be way higher and C++ may be way
 more desired. And just as the server-side interface development was driven by a
 strict set of guidelines (multiple backends, modularity with specific use
 cases...), we need to define what we want to achieve with the client-side
 abstraction. What kind of usage will be appropriate with such design.]]

[[Why isn't a router available?]

 [Advocates of tree-based routers tend to ignore the middleware-based approach
 and the other way around is also true. It happens that some even only know one
 way and don't even stop to consider that their approach isn't appropriate for
 every project. This subject will affect the life of the users *a lot* and can
 be rather polemic.

 I just provide the building blocks and you can create the router any way you
 want. Actually, I intend to implement them later, because implementing them
 now will just distract the attention of the reviewers and it'd be a waste of
 time if the review proves the core set of abstractions is wrong.

 Most of the designs I see propose dynamic routers, where you can change the
 routing rules at runtime, but this feature is rarely needed. Wouldn't be
 wonderful if you could use great syntax sugars to declare routers that receive
 as much optimization as possible at compile-time? Wouldn't be wonderful to use
 nested routers? Wouldn't be wonderful if you could collaborate the tree-based
 and middleware-based approach very easily? Maybe even some kind of
 collaboration between the statically declared routers and dynamic routers? I
 hope this will be rather polemic and will require a lot of iterations to get it
 right, maybe with a mini-review for acceptance.]]

[[Why is the library not header-only?]

 [Besides not affecting the code you *write* at all, the library demands linkage
 thanks to the reasons below:

 [itemized_list

 [It uses Ryan Dahl's HTTP C parser, which is not header-only.]

 [It uses custom error code categories, which demands static objects.]

 [Code that only needs to compiled once. This will decrease build times.]]]]

[[Why doesn't the library use a Spirit-based HTTP parser exposed to the user?]

 [Code reuse. We might do that later.]]

]

[endsect]

[section Design choices]

To convince you about the solution, I'll start the text highlighting some
problems and requirements. If you understand the problem, you'll understand why
the solution was proposed like that.

One of the wanted features for this library since the very beginning was to make
it possible to make a small change in code to expose the HTTP service through a
different communication mechanism. Like, change from embedded HTTP server to
FastCGI-exposed server.

There are several libraries who will provide some object you can use to consume
HTTP traffic from the world and will act as a request-reply door to create web
applications. Libraries who will expose a request object you can use to consume
TCP traffic and will export url and headers properties. The problem with this
approach is the coupling between HTTP messages and HTTP communication channels.

In Boost.Http, HTTP messages and HTTP communication channels are decoupled, so
it is easier to replace the communication channel later. You could easily use an
unprotected embedded HTTP server on development environment to tests and replace
it in favor of a full-blow solution during production.

Boost.Http defines some type requirements to abstract communication channels and
provide some polymorphic adapters who will type erase them. The abstraction was
specified carefully to allow robust applications. Your application will not hang
trying to live stream a video because the request was done from an `HTTP/1.0`
client. Also, your handler won't know what HTTP version (if any) the HTTP
request was made with.

Also among the wanted features was to retain the usefulness of the library
whether you're using it to power an application intended to run from an low-end
embedded device or an application intended to run on a cluster with plenty of
resources to be made use of. An embdeded device may not have the luxury to host
a pool or a cache layer, but a cluster may even demand these layers to properly
handle thousands of requests every second. With this use case in mind,
modularity was achieved.

The plan to finish such ambitious project was ["to expose an HTTP abstraction
able to make use of the HTTP power (chunking/streaming, pipelining, upgrade for
supporting channels and multiplexing for supporting channels), at the same time
that a complete separation of communication channels and HTTP messages is
achieved].

With the separation of HTTP messages and HTTP communication channels, alongside
the use of an active model (you ask by the next request instead providing a
handler and waiting for them), several of the requirements became very easy to
fulfill, such as HTTP pipelining, custom memory allocation, buffers, cache
layers and pools of objects.

With such very generalized abstractions, you may be worried about the need to
type too much to get something done. This is being solved by providing higher
level flexible abstractions, such as the file server you can already find.

[section The Boost.Http design]

Boost.Http provides an HTTP socket, which can be used to manage a pipeline of
HTTP messages (i.e. an HTTP request or an HTTP reply). HTTP is stateless and
each message coming from the same socket is independent. The HTTP socket from
Boost.Http is a concept and specific implementations from this concept may
provide more guarantees about the communication properties. The provided
`boost::http::basic_socket` implementation will handle actual HTTP traffic from
TCP sockets and you can use it to handle `HTTP/1.0` and `HTTP/1.1` traffic from
TCP and SSL sockets.

`read_state()` and `write_state()` are used to inspect the current state of
interaction and react appropriately. There are rules regarding when the socket
can mutate and change its states. Once you request the socket to read a new HTTP
request, you'll be notified as soon as the request metadata (request line and
HTTP headers) are ready, then you can progressively download the body and react
appropriately.

You'll have to inspect the socket to know whether the current message-exchange
requires `100-continue`, allows chunked entities (streaming response) and alike.
There is like two kind of replies. With atomic replies, you write the whole
message at once. With chunked message, you compose a message spreading its
construction among several API calls. You may want to use chunked messages when
you don't know the whole body in advance (e.g. reading a file, video live
stream...), but chunked messages can only be used in certain message exchanges.

You create one HTTP socket for each HTTP client and should handle them all
concurrently. In case you're using the embeddable HTTP server backend, you must
use an acceptor to initialize the `basic_socket`s' `next_layer()` and then
consume them. `basic_socket` templatize the underlying internal socket, so you
can use SSL, queue wrapping socket (to work around Asio's composed operations)
and so on.

The choice to represent the HTTP messages in separate objects and the whole
combination of this design ease supports for HTTP pipelining a lot. In passive
styles, a request is generated and generated and you must act on them. In this
active style, you explicitly request the next message, handle it and then
request another one. In this scenario, two unrelated messages won't be mixed up,
because you won't see the next message while you don't handle the current
one. The read and write states gives a mean to communicate how to use the API
and how to detect some logical errors in the application.

The choice to hide details from the HTTP connection (HTTP version, socket
object...) was done to properly support multiple backends. The ability to query
certain properties from the underlying communication channel is necessary to
achieve reliability under this model. A lot of responsibilies and expected
behaviour is documented on the type requirements for `ServerSocket` objects.

A C++11 multimap is used to represent HTTP headers because that's what HTTP
headers conceptually are. HTTP spec specifies you must handle HTTP header
elements with equivalent keys as if there was a single header where the values
are joined with commas. Some old headers don't work with this approach and their
values, when multiple elements with equivalent keys are present, must be stored
separately. The order matters, just as the C++11 definition of multimap.

Runtime-based polymorphic behaviour isn't used by default, because not all
projects are willing to pay for this price. Well defined type requirements are
provided and some polymorphic adaptors will convert models of these type
requirements to classes inheriting a single specific abstract base class.

Member-functions as opposed to member-variables are used in HTTP messages,
because some setup (e.g. a proxy who doesn't want to reformat the messages) may
want to move the HTTP parser to the HTTP message object. I want to allow a
library who will beat C servers in every aspect.

For type safety sake, the HTTP first line (request line or response's status
line) isn't part of the HTTP message object, as its attributes are variant.

As per [@https://tools.ietf.org/html/rfc7230#section-3.2.2 RFC 7230], ["a server
MUST NOT apply a request to the target resource until the entire request header
section is received, since later header fields might include conditionals,
authentication credentials, or deliberately misleading duplicate header fields
that would impact request processing], so we define an interface who will only
expose a message once the complete header section is ready. The message body can
be progressively received later. The API also unifies HTTP messages and HTTP
chunking.

URL-decomposed objects aren't used because all an HTTP backend needs is some
string-like container to push bytes. This container can implement an in-place
URL parsing algorithm and it is all solved. The generic HTTP backends you find
in Boost.Http won't care about the url concrete type and you don't need to
expect any barrier from this side.

[endsect]

[endsect]

[section Roadmap]

* C++98.
* Client-side HTTP.
* `HTTP/2.0`.
* Request-router.
* Forms.
* Cookies and sessions.
* WebSocket.
* Alternative backends.
* Expose an HTTP parser based on Boost.Spirit.
* Increase test coverage a lot.
* Benchmarks.
* Compress replies.
* WebDAV (it will depend on Boost.XML, which doesn't exist yet).
* World domination.

[endsect]
