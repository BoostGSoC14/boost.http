[preface Introduction
[quickbook 1.6]
]

[section Introduction]

This library was envisioned to solve the HTTP problem for the C++ programming
language. The proposal to solve this problem was to expose an HTTP abstraction
able to make use of the HTTP power (chunking/streaming, pipelining, upgrade for
supporting channels and multiplexing for supporting channels), at the same time
that a complete separation of communication channels and HTTP messages is
achieved.

Under this model, we refer to any abstraction fulfilling the requirements for an
HTTP socket as HTTP producer. HTTP producers will feed and process HTTP messages
to interested parties. The HTTP consumers are user-level components that will
make use of the HTTP messages. The idea to separate communication channels and
messages was proposed to handle pipelining and multiplexing elegantly, without
the need to complicate the application (HTTP consumers) logic.

The ability to query certain properties from the underlying communication
channel is necessary to achieve reliability under this model. It's important to
define this property system this early because collaboration with the HTTP
producers is key in such system. If native stream is not supported, for
instance, the application would exhaust the system memory trying to stream a
live video.

Besides providing a number of abstractions to isolate HTTP producers and HTTP
consumers, there is also a number of abstractions on top of that to ease the job
of creating applications making use of this distributed collaborative protocol.

[endsect]

[section Goals and Non-goals]

Text taken from the initial proposal[footnote
[@https://github.com/vinipsmaker/gsoc2014-boost]] (as such only lists short-term
goals):

[section Goals]

* Develop a library for Boost submission and inclusion that abstracts HTTP
  (*server side*).
* Asynchronous design that provides scalability.
* Modular design that doesn't force all abstractions to be used together.
  * The main goal of the modular design is to fit well in embeded projects
    developed for resource-constrained devices while it still provide the
    possibility and some abstractions for better performance on devices not so
    constrained, such as pools to recycle objects and threaded versions that can
    (mostly) cooperate with the same interfaces.
* Expose the HTTP power.
  * Chunked entities. A stream interface that allow live-stream.
  * 100-continue status. A feature to reduce network consumption.
  * Upgrade support. A feature required for WebSocket.
* Allow multiple backends such as FastCGI and CoAP. It will be useful also for
  HTTP 2.0. The only backend implementation developed will be the built in
  server (see the /deliverables/ section for more details).

[endsect]

[section Non-goals]

* Provide lower abstractions to the HTTP parser.
  * This project will use ready HTTP parsers, then I'll be free to focus on
    other important features.
  * It can be replaced later, because the parser interface will not be exposed
    and it won't affect code that makes use of this library.
* Provide even higher-abstractions to write template-driven MVC web applications
  quickly.
  * But it'll be possible to build such abstractions on top of the developed
    library.
  * In fact, there are a lot of higher-level abstractions competing with each
    other, providing mostly incompatible abstractions. By not targeting this
    field, this library can actually become a new base for all these
    higher-level abstractions and allow greater interoperability among them.

[endsect]

[section Long-term goals]

This section wasn't part of the initial proposal and it is meant to list
long-term goals that weren't part of the short term goals:

* Very simple HTTP client mode may be added later.
* Implement alternative HTTP producers (e.g. FastCGI, CoAP, HTTP/2.0).
* Replace the current parser (maybe using
  [@https://github.com/felipealmeida/http-parsers Felipe Almeida's]).
* Session support (RFC 6265).
* HTTP/2.0.
* WebSocket support.
* Write a few examples demonstrating how to implement request routers adopting
  different paradigms that can interoperate among them.
* Forms and file uploader parser.
* Compression support.
* Write a simple proxy example to demonstrate that this is the right API and can
  be used in many scenarios.

[endsect]

[endsect]

[section A (not that) small teaser]

No further guessing. It's time for a small usage example of the library. This
example is explored further under the [link tutorial tutorial section]. For now,
we're interested in extracting key features available from this library.

 #include <iostream>
 #include <algorithm>

 #include <boost/utility/string_ref.hpp>
 #include <boost/asio/io_service.hpp>
 #include <boost/asio/spawn.hpp>
 #include <boost/http/socket.hpp>
 #include <boost/http/algorithm.hpp>

 using namespace std;
 using namespace boost;

 int main()
 {
     asio::io_service ios;

     asio::ip::tcp::acceptor acceptor(ios, asio::ip::tcp
                                      ::endpoint(asio::ip::tcp::v6(), 8080));

     auto work = [&acceptor](asio::yield_context yield) {
         while (true) {
             try {
                 char buffer[4];
                 http::socket socket(acceptor.get_io_service(),
                                     asio::buffer(buffer));
                 std::string method;
                 std::string path;
                 http::message message;

                 cout << "About to accept a new connection" << endl;
                 acceptor.async_accept(socket.next_layer(), yield);

                 cout << "About to receive a new message" << endl;
                 socket.async_read_request(method, path, message, yield);
                 //message.body().clear(); // freeing not used resources

                 if (http::request_continue_required(message)) {
                     cout << "Continue required. About to send \"100-continue\""
                          << std::endl;
                     socket.async_write_response_continue(yield);
                 }

                 while (socket.read_state() != http::read_state::empty) {
                     cout << "Message not fully received" << endl;
                     switch (socket.read_state()) {
                     case http::read_state::message_ready:
                         cout << "About to receive some body" << endl;
                         socket.async_read_some(message, yield);
                         break;
                     case http::read_state::body_ready:
                         cout << "About to receive trailers" << endl;
                         socket.async_read_trailers(message, yield);
                         break;
                     default:;
                     }
                 }

                 //cout << "BODY:==";
                 //for (const auto &e: message.body()) {
                 //    cout << char(e);
                 //}
                 //cout << "==" << endl;

                 cout << "Message received. State = "
                      << int(socket.read_state()) << endl;
                 cout << "Method: " << method << endl;
                 cout << "Path: " << path << endl;
                 cout << "Host header: "
                      << message.headers().find("host")->second << endl;

                 std::cout << "Write state = " << int(socket.write_state())
                 << std::endl;

                 cout << "About to send a reply" << endl;

                 http::message reply;
                 const char body[] = "Foobar";
                 std::copy(body, body + sizeof(body) - 1,
                           std::back_inserter(reply.body()));

                 socket.async_write_response(200, string_ref("OK"), reply,
                                             yield);
             } catch (std::exception &e) {
                 cerr << "Aborting on exception: " << e.what() << endl;
                 std::exit(1);
             }
         };
     };

     cout << "About to spawn" << endl;
     spawn(ios, work);

     cout << "About to run" << endl;
     ios.run();

     return 0;
 }

[section The extensible model]

[#extensible_model]

The first thing we can notice from this code snippet is the /work/ lambda and
the /spawn/ function. We're writing an asynchronous software using a synchronous
flow of text. The /yield/ completion token passed as the last argument for each
asynchronous function makes the flow stop at that point until the requested
operation is complete. This call, of course, is *not* blocking and the control
will return to the executor in charge (`asio::io_service`). A better usage
pattern would be /spawning/ the function for each accepted connection and would
be easier to write and reason about with the Boost fibers. But leaving this fact
aside and focusing on the Http library solution, you could choose to not use
`asio::yield_context` and use any other completion token (or the classical
callback-based approach). This is possible thanks to the extensible model
proposed by Christopher Kohlhoff, described extensively within
['[@https://isocpp.org/files/papers/n4045.pdf N4045: Library Foundations for
Asynchronous Operations, Revision 2]].

This library adopted this model exclusively and you won't find any blocking
call. If you need blocking calls, you have the freedom to use some /block/-like
completion token.

Delving further on the code, we can see an eternal loop and a `try...catch`
block. This library will report errors through `error_code`s just like ASIO, but
the `yield` completion token will convert `error_code`s into exceptions.

[endsect]

[section ASIO familiarity]

Later on we can see that this library is very pleasant to use for any
ASIO-centered mind.

* Completion tokens received as the last argument for aync functions, like
  [link extensible_model discussed above].
* Async operations have the `async_` prefix.
* User control the bufferring mechanism, passing the opaque asio::buffer type.
* User provides /output/ arguments as references and they'll be "filled" by the
  time the operation completes.
* Memory management is left for the user.
* An active model is presented.
* Similar nomenclature.

/The ASIO way/ saved us from many problems that otherwise would force us to
propose solutions to already know problems such as:

* Object pools.
* Deferring acceptance to later on high load scenarios.
* HTTP pipelining problems.
* Partially filling response objects from different layers of abstractions.
* A wrapping/wrapped socket can take care of tasks such as
  synchronization/queueing and timeout.

[endsect]

[section The mysterious/weird/news API]

One of the maybe surprising things to start with is the use of highly structured
objects as opposed to things like opaque buffers. You pass a message object to
the initiating function and you'll have a fully decomposed object with a URL, a
method and even an associative container for the headers!!!

If you do have special memory requirements for the messages, you're free to
implementing an alternative container, as long as it fulfills the documented
`Message` concept. Conections channels and HTTP messages are *not* coupled
together. You can reuse these pieces in many many different contexts.

The uncoupled architecture is more general and it is the default mode, but let's
say you work at a more constrained environment where memory copying is banned,
for instance. You could provide your HTTP producer tied to your specific HTTP
message type implementing our ideas and you still may benefit from this
libray. This library provides some HTTP algorithms and some HTTP consumers and
these abstractions will save some time from you.

Another difference we can notice in this library is the presence of an
associated state for reading and writing messages. I believe this abstraction
can be extended to also support very simple HTTP clients. To avoid confusion, if
some member-function cannot be used for both modes (clients and servers), it'll
have one of the following prefixes:

* async_read_request
* async_read_response
* async_write_request
* async_write_response

We gave special attention to `read_state` and `write_state` to make sure it'll
also be usable for *simple* and asynchronous HTTP clients.

[endsect]

[section Remaining concerns]

You can notice that we do not use the message itself as a buffer object while
we're parsing the connection stream. We require a separate buffer to be able to
properly handle HTTP pipelining (and futurely multiplexing in =HTTP/2.0=).

Some people believe in the philosphy that events should be generated for any
processable piece of information and, therefore, an event for *every* header
should be emitted. The purpose behind this philosophy is to discard information
when no longer required (saving computing/memory resources) and rejecting
requests sooner (more safety against DoS attacks). The problem with this
thinking is that you cannot respond an HTTP message with only part of its
headers [footnote According to the HTTP RFC 7230, section 3.2.2: ["A server MUST
NOT apply a request to the target resource until the entire request header
section is received, since later header fields might include conditionals,
authentication credentials, or deliberately misleading duplicate header fields
that would impact request processing.]]. As such, we do not generate events for
single headers. And to make things worse (or better), we are targeting a general
layer and we cannot force many operations that might not even make sense in some
of them into this general abstraction.

After we standardize this core building block, we may improve the `basic_socket`
HTTP producer, by exposing some configuration options from its parser that
aren't available throught the general API (such as limiting urls size, limiting
the set of accepted methods, ...).

Our concepts may help pretty much in several scenarios, with its low-overhead
template-based polymorphism, but compile-time polymorphism is limiting in some
other scenarios (such as plugins). Therefore, we provide a set of abstractions
to do the job of type erasure for you.

And if you're thinking about threading and consumers that are feeded by multiple
producers (such as HTTP+HTTP[*S]), then worry no further. The active model used
by ASIO (and us) put user in control and you're pretty much free to define the
threading architecture of your application. And for the multiple producers
problem, just implement a generic consumer (or make use of our runtime-based
polymorphic abstractions) and you're free to go.

[endsect]

[endsect]
