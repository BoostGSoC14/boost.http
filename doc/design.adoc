[[design_choices]]
== Design choices

=== FAQ

[qanda]
Why build on top of Boost.Asio?::

  One of the requirements of Boost.Http is scalable performance. Scalable
  performance requires an asynchronous design. Asio is expected to become the
  future C++ standard for sockets. So, Asio it is.
+
Also, reuse existing std or Boost components is nice and Asio is the Boost
solution for asynchronous socket I/O.

Why {cpp11}?::

  Asynchronous code can be largely simplified with language support for
  lambdas. To speed up the development (and decrease bugs), {cpp11} was chosen,
  but interface-wise, the only real {cpp11} feature is enum classes, which can
  be emulated in {cpp98} easily.
+
C++98 support might be added later. The priority is to prove the core set of
abstractions is correct. Then I can move on the task to fatten the library. The
proof comes in the act of passing the Boost review process.
+
To be fair, I also depend on the {cpp11} definition of `multimap`, but Boost
containers can do the job easily.

Have you considered contribute to _project X/Y_?::

  https://github.com/vinipsmaker/gsoc2014-boost/blob/master/other_frameworks.md[Yes,
  I have].
+
But current Boost.Http is not like what I was expecting when I started to
writing it. Boost.Http is better. The gap between Boost.Http and other projects
became even larger. My previous research won't mention every difference.
+
Boost.Http supports pipelining. Pion has separate functions for
chunking. Boost.Http is designed for multiple backends. POCO, QtHttp and
Casablanca aren't build on top of Asio. Pion and cpp-netlib will use their own
thread-pool, instead adhering to Asio threading model.

Why is it only server-side?::

  Server-side and client-side are of interest to different
  applications. Initially, the focus was to provide a library just to
  server-side, but with the time spent on research and development, it became
  apparent that many of the proposed abstractions are also useful for
  client-side.
+
After this fact, a lot of caution was devoted to design the interface to retain
the usefulness in client-side, where it makes sense. But this is not enough. A
lot of time was spent on research just to get the server-side right and I expect
that much time (or more) to also get the client-side right.
+
Before any serious effort is spent on client-side, I want to focus on
server-side, where the application load may be way higher and C++ may be way
more desired. And just as the server-side interface development was driven by a
strict set of guidelines (multiple backends, modularity with specific use
cases...), we need to define what we want to achieve with the client-side
abstraction. What kind of usage will be appropriate with such design.

Why isn't a router available?::

  Advocates of tree-based routers tend to ignore the middleware-based approach
  and the other way around is also true. It happens that some even only know one
  way and don't even stop to consider that their approach isn't appropriate for
  every project. This subject will affect the life of the users *a lot* and can
  be rather polemic.
+
I just provide the building blocks and you can create the router any way you
want. Actually, I intend to implement them later, because implementing them now
will just distract the attention of the reviewers and it'd be a waste of time if
the review proves the core set of abstractions is wrong.
+
Most of the designs I see propose dynamic routers, where you can change the
routing rules at runtime, but this feature is rarely needed. Wouldn't be
wonderful if you could use great syntax sugars to declare routers that receive
as much optimization as possible at compile-time? Wouldn't be wonderful to use
nested routers? Wouldn't be wonderful if you could collaborate the tree-based
and middleware-based approach very easily? Maybe even some kind of collaboration
between the statically declared routers and dynamic routers? I hope this will be
rather polemic and will require a lot of iterations to get it right, maybe with
a mini-review for acceptance.

Why doesn't the library use a Spirit-based HTTP parser exposed to the user?::

  Code reuse. We might do that later.

=== Design choices

To convince you about the solution, I'll start the text highlighting some
problems and requirements. If you understand the problem, you'll understand why
the solution was proposed like that.

One of the wanted features for this library since the very beginning was to make
it possible to make a small change in code to expose the HTTP service through a
different communication mechanism. Like, change from embedded HTTP server to
FastCGI-exposed server.

There are several libraries who will provide some object you can use to consume
HTTP traffic from the world and will act as a request-reply door to create web
applications. Libraries who will expose a request object you can use to consume
TCP traffic and will export url and headers properties. The problem with this
approach is the coupling between HTTP messages and HTTP communication channels.

In Boost.Http, HTTP messages and HTTP communication channels are decoupled, so
it is easier to replace the communication channel later. You could easily use an
unprotected embedded HTTP server on development environment to tests and replace
it in favor of a full-blow solution during production.

Boost.Http defines some type requirements to abstract communication channels and
provide some polymorphic adapters who will type erase them. The abstraction was
specified carefully to allow robust applications. Your application will not hang
trying to live stream a video because the request was done from an `HTTP/1.0`
client. Also, your handler won't know what HTTP version (if any) the HTTP
request was made with.

Also among the wanted features was to retain the usefulness of the library
whether you're using it to power an application intended to run from an low-end
embedded device or an application intended to run on a cluster with plenty of
resources to be made use of. An embdeded device may not have the luxury to host
a pool or a cache layer, but a cluster may even demand these layers to properly
handle thousands of requests every second. With this use case in mind,
modularity was achieved.

The plan to finish such ambitious project was "to expose an HTTP abstraction
able to make use of the HTTP power (chunking/streaming, pipelining, upgrade for
supporting channels and multiplexing for supporting channels), at the same time
that a complete separation of communication channels and HTTP messages is
achieved".

With the separation of HTTP messages and HTTP communication channels, alongside
the use of an active model (you ask by the next request instead providing a
handler and waiting for them), several of the requirements became very easy to
fulfill, such as HTTP pipelining, custom memory allocation, buffers, cache
layers and pools of objects.

With such very generalized abstractions, you may be worried about the need to
type too much to get something done. This is being solved by providing higher
level flexible abstractions, such as the file server you can already find.

==== The what

image::request_handling.svg[]

The above image shows an overview of how to build HTTP servers using Boost.Http.

Let's assume you're going to use the provided `http::socket`, suitable for
embedding HTTP servers in your application.

You must instantiate a TCP socket acceptor and accept new connections. You
should handle all connections concurrently.

Each connection you handle is a pipeline of request-reply pair. To receive the
full request, your action may be required at several points. First, you should
receive the request metadata, then it may be necessary to issue a 100-continue
response. Then you need to issue reads for the body and the trailers until the
whole request has been received.

You're finally able to send the reply. You have two options, atomic messages or
chunked messages. Chunked messages are not always available and must check if
they can be used for each request you receive, using
`write_response_native_stream()`.

If you spread the handling logic among several functions, a good approach would
be to always share the triplet
`<communication channel, request message, response message>` around.

Still missing is URL parsing and request routing, so you must do this yourself,
possibly managing pools of message and socket objects.

This system allows you to implement powerful schedulers doing fair share of
resources over different IPs, whether the requests originate from HTTP or HTTPS,
using all cores of your CPU and deferring new work when the work load is too
high. You should be able to do all fine-grained tuning you need and also easily
create higher level that are suitable for your application. Not only that, this
library could become an interoperability layer for all higher-level that web
application developers create.

image::request.svg[]

Also, if you pay attention, you'll realize that this proposal just expose HTTP
with a message oriented abstraction. All procedures in the diagram are related
to HTTP events and actions. And this is a modern API and you can use pretty much
every modern HTTP feature (persistent streams & HTTP pipelining, chunked
entities, 100-continue status, ...). And you won't handle any parsing or
low-level detail at all. It's abstracted enough to allow alternative backends.

However, this can easily become a callback hell, and futures wouldn't help much,
given the need to use `while`-constructs. If you use coroutines, there is hope
your code will be readable. Boost.Http follows Asio extensible asynchronous
model and you're free to use callbacks, futures, coroutines or others.

==== ASIO familiarity

This library may be very pleasant to use for any ASIO-centered mind.

* Completion tokens received as the last argument for aync functions.
* Async operations have the `async_` prefix.
* User control the bufferring mechanism, passing the opaque `asio::buffer` type.
* User provides _output_ arguments as references and they'll be "filled" by the
  time the operation completes.
* Memory management is left for the user.
* An active model is presented.
* Similar nomenclature.

_The ASIO way_ saved us from many problems that otherwise would force us to
propose solutions to already know problems such as:

* Object pools.
* Deferring acceptance to later on high load scenarios.
* HTTP pipelining problems.
* Partially filling response objects from different layers of abstractions.
* A wrapping/wrapped socket can take care of tasks such as
  synchronization/queueing and timeout.

==== The mysterious/weird/news API

One of the maybe surprising things to start with is the use of highly structured
objects as opposed to things like opaque buffers. You pass a message object to
the initiating function and you'll have a fully decomposed object with an URL, a
method and even an associative container for the headers!!!

If you do have special memory requirements for the messages, you're free to
implementing an alternative container, as long as it fulfills the documented
`Message` concept. Connections channels and HTTP messages are *not* coupled
together. You can reuse these pieces in many many different contexts.

The uncoupled architecture is more general and it is the default mode, but let's
say you work at a more constrained environment where memory copying is banned,
for instance. You could provide your HTTP backend (e.g. a non-copying embedded
server) tied to your specific HTTP message type implementing our ideas and you
still may benefit from this libray. This library provides some HTTP algorithms
and some HTTP algorithms (e.g. file server) and these abstractions will save
some time from you.

Another difference in this library is the presence of an associated state for
reading and writing messages. I believe this abstraction can be extended to also
support very simple HTTP clients. To avoid confusion, if some member-function
cannot be used for both modes (clients and servers), it'll have one of the
following prefixes:

* async_read_request
* async_read_response
* async_write_request
* async_write_response

We gave special attention to `read_state` and `write_state` to make sure it'll
also be usable for *simple* and asynchronous HTTP clients.

==== The why

Boost.Http provides an HTTP socket, which can be used to manage a pipeline of
HTTP messages (i.e. an HTTP request or an HTTP reply). HTTP is stateless and
each message coming from the same socket is independent. The HTTP socket from
Boost.Http is a concept and specific implementations from this concept may
provide more guarantees about the communication properties. The reasons to
provide few guarantees are (`#1`) because we want a common denominator from
which we can provide implementation for multiple communication channels and
(`#2`) because implementation details are usually not required for the
application, which is only interested in a high-level abstraction. The provided
`boost::http::basic_socket` implementation will handle actual HTTP traffic from
TCP sockets and you can use it to handle `HTTP/1.0` and `HTTP/1.1` traffic from
TCP and SSL sockets.

`read_state()` and `write_state()` are used to inspect the current state of
interaction and react appropriately. There are rules regarding when the socket
can mutate and change its states. Once you request the socket to read a new HTTP
request, you'll be notified as soon as the request metadata (request line and
HTTP headers) are ready, then you can progressively download the body and react
appropriately. This idea is very useful to improve communication between the
library authors and application authors and also helps to create some tests.

You'll have to inspect the socket to know whether the current message-exchange
requires `100-continue`, allows chunked entities (streaming response) and alike.
There is like two kind of replies. With atomic replies, you write the whole
message at once. With chunked message, you compose a message spreading its
construction among several API calls. You may want to use chunked messages when
you don't know the whole body in advance (e.g. reading a file, video live
stream...), but chunked messages can only be used in certain message
exchanges. The reason behind providing two kind of replies is to properly
support a wider range of HTTP communication channels.

You create one HTTP socket for each HTTP client and should handle them all
concurrently. In case you're using the embeddable HTTP server backend, you must
use an acceptor to initialize the `basic_socket`s' `next_layer()` and then
consume them. `basic_socket` templatize the underlying internal socket, so you
can use SSL, queue wrapping socket (to work around Asio's composed operations)
and so on. The intention of Boost.Http is not only to generalize over data
structures and HTTP backends, but about any place where it may be helpful.

The choice to represent the HTTP messages in separate objects and the whole
combination of this design ease supports for HTTP pipelining a lot. In passive
styles, a request is generated and generated and you must act on them. In this
active style, you explicitly request the next message, handle it and then
request another one. In this scenario, two unrelated messages won't be mixed up,
because you won't see the next message while you don't handle the current
one. The read and write states gives a mean to communicate how to use the API
and how to detect some logical errors in the application.

The choice to hide details from the HTTP connection (HTTP version, socket
object...) was done to properly support multiple backends. The ability to query
certain properties from the underlying communication channel is necessary to
achieve reliability under this model. A lot of responsibilies and expected
behaviour is documented on the type requirements for `ServerSocket` objects.

A {cpp11} multimap is used to represent HTTP headers because that's what HTTP
headers conceptually are. HTTP spec specifies you must handle HTTP header
elements with equivalent keys as if there was a single header where the values
are joined with commas. Some old headers don't work with this approach and their
values, when multiple elements with equivalent keys are present, must be stored
separately. The order matters, just as the {cpp11} definition of multimap.

Runtime-based polymorphic behaviour isn't used by default, because not all
projects are willing to pay for this price. Well defined type requirements are
provided and some polymorphic adaptors will convert models of these type
requirements to classes inheriting a single specific abstract base class.

Member-functions as opposed to member-variables are used in HTTP messages,
because some setup (e.g. a proxy who doesn't want to reformat the messages) may
want to move the HTTP parser to the HTTP message object. I want to allow a
library who will beat C servers in every aspect.

For type safety sake, the HTTP first line (request line or response's status
line) isn't part of the HTTP message object, as its attributes are variant.

As per {rfc7230}, "a server MUST NOT apply a request to the target resource
until the entire request header section is received, since later header fields
might include conditionals, authentication credentials, or deliberately
misleading duplicate header fields that would impact request processing", so we
define an interface who will only expose a message once the complete header
section is ready. The message body can be progressively received later. The API
also unifies HTTP messages and HTTP chunking.

URL-decomposed objects aren't used because all an HTTP backend needs is some
string-like container to push bytes. This container can implement an in-place
URL parsing algorithm and it is all solved. The generic HTTP backends you find
in Boost.Http won't care about the url concrete type and you don't need to
expect any barrier from this side.

We do not use the message itself as a buffer object while we're parsing the
connection stream. We require a separate buffer to be able to properly handle
HTTP pipelining (and futurely multiplexing in `HTTP/2.0`).

==== The when

I couldn't resist the temptation of adding a "_when_" named section after I
already had written a "_what_" and a "_why_" section.

Just too much research time went into this proposal. Really, a lot of time. I
developed some broken HTTP projects some years ago, learned a lot of design with
really different approaches (PHP, Django, Node.js) trying to solve this problem,
developed my own serious project (https://github.com/vinipsmaker/tufao[Tufão])
and continued to study and research a lot (the HTTP spec resurrection project,
or {rfc7230}, helped *a lot*). I've gathered info around where interoperability
may be a problem if API doesn't help and what features will be desired, sooner
or later, by users, among other data. I've done real effort to gather feedback
from {cpp} programmers for quite a while already.

A special thanks to Bjørn Reese for mentoring me on Asio quirks and API general
design, the feedback which changed the proposal the most. Also a special thanks
to any friend who helped to maintain my mind at a happy state.

=== Roadmap

* {cpp98}.
* Client-side HTTP.
* `HTTP/2.0`.
* Request-router.
* Forms and file uploads.
* Cookies and sessions (RFC 6265).
* WebSocket.
* Alternative backends.
* Increase test coverage a lot.
* Benchmarks.
* Compress replies.
* WebDAV (it will depend on Boost.XML, which doesn't exist yet).
* World domination.
